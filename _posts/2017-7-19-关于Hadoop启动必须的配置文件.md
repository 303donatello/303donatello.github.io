---

layout: post
title:  "关于Hadoop启动必须的配置文件"
categories: Hadoop
tags: 云计算 Hadoop 经验
author: 303Donatello

---

* content
{:toc}
## 进程

配置文件后，理论上jps查询会有如下进程：

```
* JPS
* DataNode
* NodeManager
* NameNode
* ResourceManager
* SecondaryNameNode
```













## core-site.xml

```
<configuration>
<!--指定fs的缺省名称-->
<property>
   <name>fs.default.name</name>
   <value>hdfs://192.168.1.2:9000</value>
 </property>
<!--指定HDFS的（NameNode）的缺省路径地址：ip地址>
<property>
<name>fs.defaultFS</name>
         <value>hdfs://192.168.1.2:9000</value>
</property>
<!--指定hadoop运行时产生文件的存储目录-->
<property>
        <name>hadoop.tmp.dir</name>
        <value>/simple/hadoop-2.4.1/tmp</value>
</property>
</configuration>
```

## hdfs-site.xml

```
<configuration>
<!--指定HDFS副本的数量-->
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
       <name>dfs.name.dir</name>
       <value>/simple/Hadoop-2.4.1/hdfs/name</value>
</property>
<property>
     <name>dfs.data.dir</name>
      <value>/simple/hadoop-2.4.1/hdfs/data</value>
 </property>
</configuration>
```

## mapred-site.xml

```
<configuration>
<!--指定mr运行在yarn上>
 <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
</property>

</configuration>

```

## yarn-site.xml

```
<configuration>
<!--指定YARN的老大（ResourceManager）的地址-->
<!-- Site specific YARN configuration properties -->
<property>
<name>yarn.resourcemanager.hostname</name>
<value>192.168.1.2</value>
</property>
<!--reducer获取数据的方式-->
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
</configuration>
```

## profile

```
unset -f pathmunge
JAVA_HOME=/simple/jdk1.7.0_79
HADOOP_HOME=/simple/hadoop-2.4.1
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH


```





 
